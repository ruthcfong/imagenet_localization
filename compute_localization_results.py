"""
compute_localization_results.py

Given a bounding box file (i.e., generated by generate_bbox_file.py),
compute localization error.
"""

import os

from bs4 import BeautifulSoup
import numpy as np

from utils import str2bool, read_imdb, get_basename_without_ext


def load_annotation(ann_filename):
    """
    Load annotation file.

    Args:
        annotation file path

    Returns:
        BeautifulSoup structure: the annotation labels loaded as a
            BeautifulSoup data structure
    """
    xml = ""
    with open(ann_filename) as f:
        xml = f.readlines()
    xml = ''.join([line.strip('\t') for line in xml])
    return BeautifulSoup(xml, "lxml")


def load_objs(ann_filename):
    """
    Load objects from annotation file.

    Args:
        ann_filename: String, path to annotation file.

    Returns:
        data: dict containing bounding box and key point coordinates.
    """
    anno = load_annotation(ann_filename)
    data = {}
    objs = anno.findAll('object')
    for obj in objs:
        obj_names = obj.findChildren('name')
        for name_tag in obj_names:
            label = str(name_tag.contents[0])
            bbox = obj.findChildren('bndbox')[0]
            xmin = int(bbox.findChildren('xmin')[0].contents[0])
            ymin = int(bbox.findChildren('ymin')[0].contents[0])
            xmax = int(bbox.findChildren('xmax')[0].contents[0])
            ymax = int(bbox.findChildren('ymax')[0].contents[0])
            if label in data:
                data[label].append([xmin, ymin, xmax, ymax])
            else:
                data[label] = [[xmin, ymin, xmax, ymax]]
            for point in obj.findChildren('point'):
                x = float(point.findChildren('x')[0].contents[0])
                y = float(point.findChildren('y')[0].contents[0])
                keypoint = str(point.findChildren('class')[0].contents[0])
                if keypoint in data:
                    data[keypoint].append([x,y])
                else:
                    data[keypoint] = [[x,y]]
    return data


def compute_overlap(bb, objs, label):
    """
    Compute the overlap between predicted bbox and label and gt bbox and label.

    Args:
        bb: List, contains predicted bounding box coordinates for an image.
        objs: dict, contains ground truth bounding boxes for all objects
            in an image.
        label: String, predicted label for an image.

    Returns:
        ov_vector: List, contains percentile overlap for each object.
    """
    assert(len(bb) == 4)
    ov_vector = []
    for k in objs.keys():
        if k != label:
            continue
        for i in range(len(objs[k])):
            bbgt = objs[k][i]
            bi=[max(bb[0],bbgt[0]), max(bb[1],bbgt[1]),
                min(bb[2],bbgt[2]), min(bb[3],bbgt[3])]
            iw=bi[2]-bi[0]+1
            ih=bi[3]-bi[1]+1
            ov = -1
            if iw>0 and ih>0:
                # Compute overlap as area of intersection / area of union.
                ua=((bb[2]-bb[0]+1)*(bb[3]-bb[1]+1)
                       +(bbgt[2]-bbgt[0]+1)*(bbgt[3]-bbgt[1]+1)
                       -iw*ih)
                ov=iw*ih/float(ua)
            ov_vector.append(ov)
    return ov_vector


def compute_localization_results(bb_file,
                                 imdb_file,
                                 annotation_dir,
                                 verbose=False,
                                 blacklist_path='data/ILSVRC2014_clsloc_validation_blacklist.txt',
                                 force_full=True):
    """
    Compute ImageNet localization error.

    Args:
        bb_file: String, path to predicted bounding box file.
        imdb_file: String, path to imdb file with image names and labels
            (assuming that bb_file is sorted by imdb_file).
        annotation_dir: String, path to dir containing annotation files.
        verbose: Boolean, if True, print progress.
        blacklist_path: String, path to ImageNet blacklist.
        force_full: Boolean, if True, force number of bounding boxes to match
            number of images.

    Returns:
        tuple containing
            1. localization error rate,
            2. a binary list reporting whether localization was correct for
               each image, and
            3. overlap, a list reporting the maximum overlap between
               the predicted bounding box and ground truth bounding box
               for each image.
    """
    if verbose:
        print('Sort annotation files to match order in imdb file.')

    # Get order of image files from imdb file.
    (rel_img_paths, _) = read_imdb(imdb_file)
    num_examples = len(rel_img_paths)

    img_names = get_basename_without_ext(rel_img_paths)

    sorted_idx = np.argsort(img_names)
    sorted_to_order_idx = {j:i for i, j in enumerate(sorted_idx)}
    order_idx = np.array([sorted_to_order_idx[j] for j in range(num_examples)])

    # Order annotation files based on imdb order.
    ann_paths = np.sort([os.path.join(annotation_dir, f)
                         for f in os.listdir(annotation_dir)])

    # TODO(ruthfong): Support situation where number of annotation paths is
    # larger than the number of examples (and select the correct
    # annotation paths).
    assert(len(ann_paths) == num_examples)
    ann_paths = ann_paths[order_idx]

    # Verify ordering of annotation files.
    assert(np.all(img_names == get_basename_without_ext(ann_paths)))

    # Load bounding boxes from bb_file.
    if verbose:
        print('Loading bounding boxes from', bb_file)
    bb_data = np.loadtxt(bb_file, dtype=str)
    bb_labels = bb_data[:,0].astype(str)
    bbs = bb_data[:,1:].astype(int)

    if force_full:
        assert num_examples == len(bb_labels)
    else:
        if num_examples != len(bb_labels):
            print(f'Number of expected labels ({num_examples}) does not match ' \
                  f'number of actual labels ({len(bb_labels)}).')
            num_examples = len(bb_labels)

    # TODO(ruthfong): Implement this more robustly.
    # Add to blacklist for ImageNet validation set.
    blacklist = np.zeros(num_examples)
    if num_examples == 50000:
        blacklist_idx = np.loadtxt(blacklist_path, dtype=int) - 1
        blacklist[blacklist_idx] = 1

    # Iterate over every example and compute overlap.
    res = np.zeros(num_examples, dtype=int)
    overlap = np.zeros(num_examples)
    no_masks = np.zeros(num_examples)
    for i in range(num_examples):
        # Skip blacklisted examples.
        if blacklist[i]:
            continue
        # Automatically fail examples with coordinates [-1, -1, -1, -1] - no bbox.
        if np.all(bbs[i] == -1):
            print('No BBox')
            res[i] = True
            continue
        if np.all(bbs[i] == -2):
            print('Mask not computed')
            res[i] = False
            no_masks[i] = True
            continue
        objs = load_objs(ann_paths[i])
        ov_vector = compute_overlap(bbs[i], objs, bb_labels[i])
        if len(ov_vector) == 0:
            print("No Overlap")
            res[i] = True
            overlap[i] = False
            continue
        try:
            res[i] = max(ov_vector) < 0.5
        except:
            print(i, ov_vector)
        overlap[i] = max(ov_vector)

    print(res)
    # Compute overall localization error.
    err = res.sum()/float(num_examples - blacklist.sum() - no_masks.sum())
    if verbose:
        print('Localization Error:', err)

    return (err, res, overlap, no_masks, blacklist.sum())


if __name__ == '__main__':
    import argparse
    import sys
    import traceback

    try:
        parser = argparse.ArgumentParser()
        parser.register('type', 'bool', str2bool)
        parser.add_argument('--bb_file', type=str,
                            default='/scratch/shared/slow/mandela/bbox_results/bb_val_pertrubations_mean_5.00.txt',
                            help='Text file with predicted bounding boxes.')
        parser.add_argument('--imdb_file', type=str,
                            default='./data/val_imdb_0_1000.txt',
                            help='File with relative image paths and labels.')
        parser.add_argument('--annotation_dir', type=str,
                            default='/datasets/imagenet14/cls_loc/val',
                            help='Path to dir with ImageNet annotations.')
        parser.add_argument('--verbose', type='bool', default=True)
        parser.add_argument('--force_full', type='bool', default=True)
        parser.add_argument('--blacklist_path', type=str,
                            default='data/ILSVRC2014_clsloc_validation_blacklist.txt')
        args = parser.parse_args()

        compute_localization_results(bb_file=args.bb_file,
                                     imdb_file=args.imdb_file,
                                     annotation_dir=args.annotation_dir,
                                     verbose=args.verbose,
                                     blacklist_path=args.blacklist_path,
                                     force_full=args.force_full)
    except:
        traceback.print_exc(file=sys.stdout)
        sys.exit(1)
